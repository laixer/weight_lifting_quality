---
title: "Weight Lifting Quality Assesment"
output: html_document
---

```{r}
library(caret)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(parallel)
library(reshape2)
library(doMC)
```

Enable parallelization for training.

```{r}
registerDoMC(cores = 4)
```

Load the data.

```{r}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

## Data Visualization

Extract a sample of the data for visualization.

```{r}
carlitos_good_lifts <- training %>% 
  filter(user_name == "carlitos" & classe == "A") %>%
  mutate(raw_timestamp = ((raw_timestamp_part_1 - min(raw_timestamp_part_1)) * 
                            1000000 + raw_timestamp_part_2) / 1000000.0)

belt_features <- c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt",
                   "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", 
                   "accel_belt_x", "accel_belt_y", "accel_belt_z", 
                   "magnet_belt_x", "magnet_belt_y", "magnet_belt_z")
arm_features <- c("roll_arm", "pitch_arm", "yaw_arm", "total_accel_arm", 
                  "gyros_arm_x", "gyros_arm_y", "gyros_arm_z", "accel_arm_x",
                  "accel_arm_y", "accel_arm_z", "magnet_arm_x", "magnet_arm_y",
                  "magnet_arm_z")
dumbbell_features <- c("roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell",
                       "total_accel_dumbbell", "gyros_dumbbell_x", 
                       "gyros_dumbbell_y", "gyros_dumbbell_z", 
                       "accel_dumbbell_x", "accel_dumbbell_y", 
                       "accel_dumbbell_z", "magnet_dumbbell_x", 
                       "magnet_dumbbell_y", "magnet_dumbbell_z")
forearm_features <- c("roll_forearm", "pitch_forearm", "yaw_forearm",
                      "total_accel_forearm", "gyros_forearm_x", 
                      "gyros_forearm_y", "gyros_forearm_z", "accel_forearm_x",
                      "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x",
                      "magnet_forearm_y", "magnet_forearm_z")

carlitos_good_lifts.narrow <- melt(carlitos_good_lifts, 
                                   id.vars = c("raw_timestamp"), 
                                   measure.vars = c(belt_features,
                                                    arm_features,
                                                    dumbbell_features,
                                                    forearm_features))
carlitos_good_lifts.narrow$source <- 
  ifelse(carlitos_good_lifts.narrow$variable %in% belt_features, "belt", 
  ifelse(carlitos_good_lifts.narrow$variable %in% arm_features, "arm",
  ifelse(carlitos_good_lifts.narrow$variable %in% dumbbell_features, "dumbbell",
  ifelse(carlitos_good_lifts.narrow$variable %in% forearm_features, "forearm", 
         "UNKNOWN"))))

carlitos_good_lifts.narrow$variable <- 
  gsub("_(belt|arm|dumbbell|forearm)", "", carlitos_good_lifts.narrow$variable)
```


```{r, fig.width=10}
ggplot(carlitos_good_lifts.narrow,  aes(raw_timestamp, value, color=variable)) + 
  facet_wrap(~source, ncol = 1) +
  geom_line() + 
  scale_x_continuous(breaks = 1:40)
```

We see cyclic patterns as the person performs weight lifts.

Let's define a function that will responsible for extracting features that will
be used in training. To start with, we will use all available features.

```{r}
extract_features <- function(df) {
  return(select(df, one_of(
    "classe", 
    "user_name", 
    belt_features, 
    arm_features, 
    dumbbell_features, 
    forearm_features)))
}
```

## Random Forest Model

```{r train_rf_model, cache=TRUE}
fit_control_rf <- trainControl(method = "cv", number = 10, verboseIter = TRUE)
set.seed(94610348)
fit_rf <- train(classe ~ .,
                data = extract_features(training),
                method = "rf",
                trControl = fit_control_rf)
```

Let's take a peek at the results.

```{r}
fit_rf$results
```

This model has 99.5% accuraccy. The model is performant and accurate enough
that there's no need to cherry pick features.

## Neural Network Model

Increase the number of hidden units to provide a better fit. 
Apply PCA to the data to reduce the number of features to make the computations 
feasable.

```{r train_nn_model, cache=TRUE}
fit_control_nn <- trainControl(method = "cv", number = 10, verboseIter = TRUE)
tune_grid_nn <- expand.grid(.decay = c(0), .size = c(200))

set.seed(10482349)
fit_nn <- train(classe ~ ., 
                data = extract_features(training), 
                method = "nnet", 
                trControl = fit_control_nn, 
                trace = FALSE, 
                tuneGrid = tune_grid_nn,
                MaxNWts = 10000,
                preProcess = c("center", "scale", "pca"))
```

Neural network results.

```{r}
fit_nn$results
fit_nn$finalModel
```

We are able to achieve 98.67% accurracy using 25 features.

## Support Vector Machine Model

Try different values of the regularization parameter C.

```{r train_svm_model, cache=TRUE}
fit_control_svm <- trainControl(method = "cv", number = 10, verboseIter = TRUE)
tune_grid_svm <- expand.grid(.sigma = 0.01263598, .C = c(1, 10, 100))

set.seed(8401650)
fit_svm <- train(classe ~ ., 
                data = extract_features(training), 
                method = "svmRadial", 
                trControl = fit_control_svm, 
                tuneGrid = tune_grid_svm,
                trace = FALSE, 
                preProcess = c("center", "scale"))
```

How are the SVM results?

```{r}
fit_svm$results
```

Accurracy is 99.49%.

## Combined Model

Let's train a random forest model that combines all the three models.

```{r train_combined_model, cache=TRUE}
predict_rf <- predict(fit_rf, newdata=training)
predict_nn <- predict(fit_nn, newdata=training)
predict_svm <- predict(fit_svm, newdata=training)
training_combined <- data.frame(classe=training$classe, 
                                classe_rf=predict_rf,
                                classe_nn=predict_nn,
                                classe_svm=predict_svm)
fit_combined <- train(classe ~ ., data = training_combined, method = "rf")

```

On how many examples do all three models agree? At least two?

```{r}
sum((predict_rf == predict_nn) & (predict_nn == predict_svm)) / nrow(training)
sum((predict_rf == predict_nn) | 
      (predict_nn == predict_svm) | 
      (predict_rf == predict_svm)) / nrow(training)
```

## Final Predictions

Make predictions on the test data.

```{r}
test_predict_rf <- predict(fit_rf, newdata=testing)
test_predict_nn <- predict(fit_nn, newdata=testing)
test_predict_svm <- predict(fit_svm, newdata=testing)
testing_combined <- data.frame(classe_rf=test_predict_rf,
                               classe_nn=test_predict_nn,
                               classe_svm=test_predict_svm)
predict_final <- predict(fit_combined, newdata=testing_combined)
```

On what percentage of test data to the models agree on?

```{r}
sum((test_predict_rf == test_predict_nn) & 
      (test_predict_nn == test_predict_svm)) / nrow(testing)
```

The models agree on all the test examples.
Write out the predictions to files.

```{r}
pml_write_files = function(x){
   n = length(x)   
   for(i in 1:n){
     filename = paste0("problem_id_",i,".txt")
     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
   }
}
 
pml_write_files(predict_final)
```